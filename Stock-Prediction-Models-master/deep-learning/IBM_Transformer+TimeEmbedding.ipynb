{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6zxz6xZyWb2",
    "outputId": "d80a4b3f-7fb0-4e51-bfa6-879b0b1edefc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:38:30.098854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2021-12-08 22:38:30.136180: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2021-12-08 22:38:30.145857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5629a8a0b5a0 executing computations on platform Host. Devices:\n",
      "2021-12-08 22:38:30.145941: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2021-12-08 22:38:30.147874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-08 22:38:31.902028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:1b:00.0\n",
      "2021-12-08 22:38:31.906052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:1c:00.0\n",
      "2021-12-08 22:38:31.908450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:60:00.0\n",
      "2021-12-08 22:38:31.912478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:62:00.0\n",
      "2021-12-08 22:38:31.916651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:b1:00.0\n",
      "2021-12-08 22:38:31.920652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:b2:00.0\n",
      "2021-12-08 22:38:31.924645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:da:00.0\n",
      "2021-12-08 22:38:31.928618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:dc:00.0\n",
      "2021-12-08 22:38:31.928905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-12-08 22:38:31.930281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-12-08 22:38:31.931623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-12-08 22:38:31.932002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-12-08 22:38:31.933557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-12-08 22:38:31.934689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-12-08 22:38:31.938163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-08 22:38:32.012989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2021-12-08 22:38:32.013057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-12-08 22:38:32.064221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-08 22:38:32.064251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 5 6 7 \n",
      "2021-12-08 22:38:32.064261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y Y Y Y Y \n",
      "2021-12-08 22:38:32.064268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y Y Y Y Y \n",
      "2021-12-08 22:38:32.064274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y Y Y Y Y \n",
      "2021-12-08 22:38:32.064280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N Y Y Y Y \n",
      "2021-12-08 22:38:32.064286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   Y Y Y Y N Y Y Y \n",
      "2021-12-08 22:38:32.064292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 5:   Y Y Y Y Y N Y Y \n",
      "2021-12-08 22:38:32.064297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 6:   Y Y Y Y Y Y N Y \n",
      "2021-12-08 22:38:32.064303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 7:   Y Y Y Y Y Y Y N \n",
      "2021-12-08 22:38:32.120232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 29765 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.131515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 30581 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1c:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.139049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:2 with 877 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:60:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.151011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:3 with 30576 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.163114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:4 with 30581 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b1:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.175113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:5 with 30579 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.188744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:6 with 30581 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:da:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.203126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:7 with 30581 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:dc:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.209896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5629ad0f18e0 executing computations on platform CUDA. Devices:\n",
      "2021-12-08 22:38:32.209923: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209931: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209936: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209942: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209947: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209953: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209958: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.209964: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-12-08 22:38:32.215460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:1b:00.0\n",
      "2021-12-08 22:38:32.221646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:1c:00.0\n",
      "2021-12-08 22:38:32.224824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:60:00.0\n",
      "2021-12-08 22:38:32.231130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:62:00.0\n",
      "2021-12-08 22:38:32.235131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:b1:00.0\n",
      "2021-12-08 22:38:32.238890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:b2:00.0\n",
      "2021-12-08 22:38:32.242903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:da:00.0\n",
      "2021-12-08 22:38:32.246919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: \n",
      "name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:dc:00.0\n",
      "2021-12-08 22:38:32.246960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-12-08 22:38:32.246977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-12-08 22:38:32.246990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-12-08 22:38:32.247003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-12-08 22:38:32.247016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-12-08 22:38:32.247029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-12-08 22:38:32.247042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-08 22:38:32.308937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2021-12-08 22:38:32.312828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-08 22:38:32.312859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 5 6 7 \n",
      "2021-12-08 22:38:32.312874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y Y Y Y Y \n",
      "2021-12-08 22:38:32.312886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y Y Y Y Y \n",
      "2021-12-08 22:38:32.312898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y Y Y Y Y \n",
      "2021-12-08 22:38:32.312910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N Y Y Y Y \n",
      "2021-12-08 22:38:32.312921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   Y Y Y Y N Y Y Y \n",
      "2021-12-08 22:38:32.312932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 5:   Y Y Y Y Y N Y Y \n",
      "2021-12-08 22:38:32.312944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 6:   Y Y Y Y Y Y N Y \n",
      "2021-12-08 22:38:32.312955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 7:   Y Y Y Y Y Y Y N \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:38:32.351168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 29765 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.354980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 30581 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1c:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.357445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:2 with 877 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:60:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.361406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:3 with 30576 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.365458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:4 with 30581 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b1:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.369438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:5 with 30579 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.373486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:6 with 30581 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:da:00.0, compute capability: 7.0)\n",
      "2021-12-08 22:38:32.377543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:7 with 30581 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:dc:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import losses\n",
    "print('Tensorflow version: {}'.format(tf.__version__))\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gpu_device_name = tf.test.gpu_device_name()\n",
    "print(gpu_device_name)\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykFSM9LT54LR"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tushare as ts\n",
    "# pro = ts.pro_api('f198ddf6f6c8918413793b567bed6269e931f433abd746b26a3c2668')\n",
    "# dd = pro.daily(ts_code='000001.SZ', start_data='20180701', end_data='20201119')\n",
    "# dd.to_csv('pro001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Acgb31zy5lcD"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "seq_len = 128\n",
    "d_k = 32\n",
    "d_v = 32\n",
    "n_heads = 32\n",
    "ff_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WhTPe6I6sDu"
   },
   "source": [
    "## TimeVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUawOlTD5ljR"
   },
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "  def __init__(self, seq_len, **kwargs):\n",
    "    super(Time2Vector, self).__init__()\n",
    "    self.seq_len = seq_len\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "    self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    '''Calculate linear and periodic time features'''\n",
    "    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) \n",
    "    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    \n",
    "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "   \n",
    "  def get_config(self): # Needed for saving and loading model with custom layer\n",
    "    config = super().get_config().copy()\n",
    "    config.update({'seq_len': self.seq_len})\n",
    "    return config\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJZOW8d56wyJ"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Veb1wu_5lhE"
   },
   "outputs": [],
   "source": [
    "class SingleAttention(Layer):\n",
    "  def __init__(self, d_k, d_v):\n",
    "    super(SingleAttention, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.query = Dense(self.d_k, \n",
    "                       input_shape=input_shape, \n",
    "                       kernel_initializer='glorot_uniform', \n",
    "                       bias_initializer='glorot_uniform')\n",
    "    \n",
    "    self.key = Dense(self.d_k, \n",
    "                     input_shape=input_shape, \n",
    "                     kernel_initializer='glorot_uniform', \n",
    "                     bias_initializer='glorot_uniform')\n",
    "    \n",
    "    self.value = Dense(self.d_v, \n",
    "                       input_shape=input_shape, \n",
    "                       kernel_initializer='glorot_uniform', \n",
    "                       bias_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "    q = self.query(inputs[0])\n",
    "    k = self.key(inputs[1])\n",
    "\n",
    "    attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "    \n",
    "    v = self.value(inputs[2])\n",
    "    attn_out = tf.matmul(attn_weights, v)\n",
    "    return attn_out    \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class MultiAttention(Layer):\n",
    "  def __init__(self, d_k, d_v, n_heads):\n",
    "    super(MultiAttention, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "    self.n_heads = n_heads\n",
    "    self.attn_heads = list()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    for n in range(self.n_heads):\n",
    "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
    "    \n",
    "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
    "    self.linear = Dense(input_shape[0][-1], \n",
    "                        input_shape=input_shape, \n",
    "                        kernel_initializer='glorot_uniform', \n",
    "                        bias_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "    concat_attn = tf.concat(attn, axis=-1)\n",
    "    multi_linear = self.linear(concat_attn)\n",
    "    return multi_linear   \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "    super(TransformerEncoder, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "    self.n_heads = n_heads\n",
    "    self.ff_dim = ff_dim\n",
    "    self.attn_heads = list()\n",
    "    self.dropout_rate = dropout\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "    self.attn_dropout = Dropout(self.dropout_rate)\n",
    "    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n",
    "    self.ff_conv1D_se1 = Conv1D(filters=self.ff_dim//2, kernel_size=1)\n",
    "    self.ff_conv1D_se2 = Conv1D(filters=self.ff_dim, kernel_size=1,activation='sigmoid')\n",
    "    self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
    "    self.ff_dropout = Dropout(self.dropout_rate)\n",
    "    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "  \n",
    "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "    attn_layer = self.attn_multi(inputs)\n",
    "    attn_layer = self.attn_dropout(attn_layer)\n",
    "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "    ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "    aa_layer = self.ff_conv1D_se1(ff_layer)\n",
    "    aa_layer = self.ff_dropout(aa_layer)\n",
    "    aa_layer = self.ff_conv1D_se2(aa_layer)\n",
    "    aa_layer = self.ff_dropout(aa_layer)\n",
    "    ff_layer = aa_layer+ff_layer\n",
    "    ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "    ff_layer = self.ff_dropout(ff_layer)\n",
    "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "    return ff_layer \n",
    "\n",
    "  def get_config(self): # Needed for saving and loading model with custom layer\n",
    "    config = super().get_config().copy()\n",
    "    config.update({'d_k': self.d_k,\n",
    "                   'd_v': self.d_v,\n",
    "                   'n_heads': self.n_heads,\n",
    "                   'ff_dim': self.ff_dim,\n",
    "                   'attn_heads': self.attn_heads,\n",
    "                   'dropout_rate': self.dropout_rate})\n",
    "    return config          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXm-L7Y7SXY4"
   },
   "source": [
    "# Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWDD3gi0SkBT"
   },
   "source": [
    "## Moving Average - Load Tesla data again, to apply rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge(number):\n",
    "    if number>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla_path = '/home/changjiang_2/BDA/Stock-Prediction-Models-master/deep-learning/pro001.csv'\n",
    "df = pd.read_csv(Tesla_path, delimiter=',', usecols=['ts_code','Date','Open','High','Low','Close','pre_close','change','pct_chg','Volume','amount'])\n",
    "df['Volume'].replace(to_replace=0, method='ffill', inplace=True)\n",
    "df['pct_chg'].replace(to_replace=0, method='ffill', inplace=True)\n",
    "df['change'].replace(to_replace=0, method='ffill', inplace=True)\n",
    "df['amount'].replace(to_replace=0, method='ffill', inplace=True)\n",
    "lis = df['pct_chg']\n",
    "lising = []\n",
    "for l in lis:\n",
    "    new = charge(l)\n",
    "    lising.append(new)\n",
    "df.insert(11,'label',lising)\n",
    "df.sort_values('Date', inplace=True)\n",
    "df.drop(labels='ts_code',axis=1,inplace=True)\n",
    "# df.drop(labels='pre_close',axis=1,inplace=True)\n",
    "# df.drop(labels='pct_chg',axis=1,inplace=True)\n",
    "# df.drop(labels='change',axis=1,inplace=True)\n",
    "# df.drop(labels='amount',axis=1,inplace=True)\n",
    "# df[['Open', 'High', 'Low', 'Close','Volume']] = df[['Open', 'High', 'Low', 'Close','Volume']].rolling(10).mean()\n",
    "# df.drop('index')\n",
    "df.dropna(how='any', axis=0, inplace=True) \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "I6ShhyS6Sajz",
    "outputId": "c9f3e294-d45f-4587-938b-0d00017e75e0"
   },
   "outputs": [],
   "source": [
    "# Tesla_path = '../dataset/TSLA.csv'\n",
    "\n",
    "# df = pd.read_csv(Tesla_path, delimiter=',', usecols=['Date', 'Open', 'High', 'Low', 'Close','Adj Close','Volume'])\n",
    "# df.drop(labels='Adj Close',axis=1,inplace=True)\n",
    "# # Replace 0 to avoid dividing by 0 later on\n",
    "# df['Volume'].replace(to_replace=0, method='ffill', inplace=True) \n",
    "# df.sort_values('Date', inplace=True)\n",
    "\n",
    "# # Apply moving average with a window of 10 days to all columns\n",
    "# df[['Open', 'High', 'Low', 'Close','Volume']] = df[['Open', 'High', 'Low', 'Close','Volume']].rolling(10).mean() \n",
    "\n",
    "# # Drop all rows with NaN values\n",
    "# df.dropna(how='any', axis=0, inplace=True) \n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh7gRX0FS-xZ"
   },
   "source": [
    "## Moving Average - Plot daily Tesla closing prices and volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "JT97nI1sSafp",
    "outputId": "5f49e92f-9ba3-4eda-f7b1-9f33e7ebe028"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "st = fig.suptitle(\"Tesla Close Price and Volume\", fontsize=20)\n",
    "st.set_y(0.92)\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(df['Close'], label='Tesla Close Price')\n",
    "ax1.set_xticks(range(0, df.shape[0], 30))\n",
    "ax1.set_xticklabels(df['Date'].loc[::30])\n",
    "ax1.set_ylabel('Close Price', fontsize=18)\n",
    "ax1.legend(loc=\"upper left\", fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaGiU_wgTYqu"
   },
   "source": [
    "## Moving Average - Calculate normalized percentage change for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "xOQVdn5TSaZs",
    "outputId": "e5a2ec9e-2f3a-4e03-b545-a0d5172acaea"
   },
   "outputs": [],
   "source": [
    "# '''Calculate percentage change'''\n",
    "\n",
    "# # df['Open'] = df['Open'].pct_change() # Create arithmetic returns column\n",
    "# # df['High'] = df['High'].pct_change() # Create arithmetic returns column\n",
    "# # df['Low'] = df['Low'].pct_change()# Create arithmetic returns column\n",
    "# # df['Close'] = df['Close'].pct_change() # Create arithmetic returns column\n",
    "# # df['Volume'] = df['Volume'].pct_change()\n",
    "\n",
    "# df.dropna(how='any', axis=0, inplace=True) # Drop all rows with NaN values\n",
    "\n",
    "# ###############################################################################\n",
    "# '''Create indexes to split dataset'''\n",
    "\n",
    "times = sorted(df.index.values)\n",
    "last_10pct = sorted(df.index.values)[-int(0.1*len(times))] # Last 10% of series\n",
    "last_20pct = sorted(df.index.values)[-int(0.2*len(times))] # Last 20% of series\n",
    "\n",
    "# ###############################################################################\n",
    "# '''Normalize price columns'''\n",
    "# #\n",
    "# min_return = min(df[(df.index < last_20pct)][['Open', 'High', 'Low', 'Close']].min(axis=0))\n",
    "# max_return = max(df[(df.index < last_20pct)][['Open', 'High', 'Low', 'Close']].max(axis=0))\n",
    "\n",
    "# # Min-max normalize price columns (0-1 range)\n",
    "# df['Open'] = (df['Open'] - min_return) / (max_return - min_return)\n",
    "# df['High'] = (df['High'] - min_return) / (max_return - min_return)\n",
    "# df['Low'] = (df['Low'] - min_return) / (max_return - min_return)\n",
    "# df['Close'] = (df['Close'] - min_return) / (max_return - min_return)\n",
    "\n",
    "# ###############################################################################\n",
    "# '''Normalize volume column'''\n",
    "\n",
    "# min_volume = df[(df.index < last_20pct)]['Volume'].min(axis=0)\n",
    "# max_volume = df[(df.index < last_20pct)]['Volume'].max(axis=0)\n",
    "\n",
    "# # Min-max normalize volume columns (0-1 range)\n",
    "# df['Volume'] = (df['Volume'] - min_volume) / (max_volume - min_volume)\n",
    "\n",
    "###############################################################################\n",
    "'''Create training, validation and test split'''\n",
    "\n",
    "df_train = df[df.index<last_20pct] # Training data are 80% of total data\n",
    "df_val = df[(df.index >= last_20pct) & (df.index < last_10pct)]\n",
    "df_test = df[df.index>=last_10pct]\n",
    "\n",
    "# Remove date column\n",
    "df_train.drop(columns=['Date'], inplace=True)\n",
    "df_val.drop(columns=['Date'], inplace=True)\n",
    "df_test.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "# Convert pandas columns into arrays\n",
    "train_data = df_train.values\n",
    "val_data = df_val.values\n",
    "test_data = df_test.values\n",
    "print('Training data shape: {}'.format(train_data.shape))\n",
    "# print('Validation data shape: {}'.format(val_data.shape))\n",
    "print('Test data shape: {}'.format(test_data.shape))\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_val.head())\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Moj1_tbiTfdc"
   },
   "source": [
    "## Moving Average - Plot daily changes of close price and volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 792
    },
    "id": "UfHJUSEPSaWi",
    "outputId": "110e6214-8793-44a3-d3cd-fb004a75d28d"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12))\n",
    "st = fig.suptitle(\"Data Separation\", fontsize=20)\n",
    "st.set_y(0.95)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(np.arange(train_data.shape[0]), df_train['Close'], label='Training data')\n",
    "\n",
    "ax1.plot(np.arange(train_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]), df_val['Close'], label='Validation data')\n",
    "\n",
    "ax1.plot(np.arange(train_data.shape[0]+val_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]+test_data.shape[0]), df_test['Close'], label='Test data')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Closing Returns')\n",
    "ax1.set_title(\"Close Price\", fontsize=18)\n",
    "ax1.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(np.arange(train_data.shape[0]), df_train['Volume'], label='Training data')\n",
    "\n",
    "ax2.plot(np.arange(train_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]), df_val['Volume'], label='Validation data')\n",
    "\n",
    "ax2.plot(np.arange(train_data.shape[0]+val_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]+test_data.shape[0]), df_test['Volume'], label='Test data')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Normalized Volume Changes')\n",
    "ax2.set_title(\"Volume\", fontsize=18)\n",
    "ax2.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkh2TIurTjOO"
   },
   "source": [
    "## Moving Average - Create chunks of training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train, y_train = [], []\n",
    "for i in range(seq_len, len(train_data)):\n",
    "  X_train.append(train_data[:,:9][i-seq_len:i]) # Chunks of training data with a length of 128 df-rows\n",
    "  y_train.append(train_data[:, 9][i]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Validation data\n",
    "X_val, y_val = [], []\n",
    "for i in range(seq_len, len(val_data)):\n",
    "    X_val.append(val_data[:,:9][i-seq_len:i])\n",
    "    y_val.append(val_data[:, 9][i])\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Test data\n",
    "X_test, y_test = [], []\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    X_test.append(test_data[:,:9][i-seq_len:i])\n",
    "    y_test.append(test_data[:, 9][i])    \n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "print('Training set shape', X_train.shape, y_train.shape)\n",
    "print('Validation set shape', X_val.shape, y_val.shape)\n",
    "print('Testing set shape' ,X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "O4YOIvAuTj4S",
    "outputId": "13902840-6cb9-46ff-9256-fc68dcd61296"
   },
   "outputs": [],
   "source": [
    "# # Training data\n",
    "# X_train, y_train = [], []\n",
    "# for i in range(seq_len, len(train_data)-5):\n",
    "#   X_train.append(train_data[i-seq_len:i]) # Chunks of training data with a length of 128 df-rows\n",
    "#   y_train.append(train_data[:, 3][i+5]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# ###############################################################################\n",
    "\n",
    "# # # Validation data\n",
    "# # X_val, y_val = [], []\n",
    "# # for i in range(seq_len, len(val_data)):\n",
    "# #     X_val.append(val_data[i-seq_len:i])\n",
    "# #     y_val.append(val_data[:, 3][i])\n",
    "# # X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "# ###############################################################################\n",
    "\n",
    "# # Test data\n",
    "# X_test, y_test = [], []\n",
    "# for i in range(seq_len, len(test_data)-5):\n",
    "#     X_test.append(test_data[i-seq_len])\n",
    "#     y_test.append(test_data[:, 3][i+5])\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# # print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ns21gno_T2xy"
   },
   "source": [
    "## Moving Average - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_1oy3O71Tjyv",
    "outputId": "c431669a-ae34-42bc-b27c-3a40b20b0051"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  '''Initialize time and transformer layers'''\n",
    "  time_embedding = Time2Vector(seq_len)\n",
    "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "  normall = LayerNormalization(axis=2)\n",
    "  normal_first = LayerNormalization(axis=-1)\n",
    "  normal_batch = BatchNormalization(axis=2)\n",
    "  # input_shape = (2,seq_len,7)\n",
    "  '''Construct model'''\n",
    "  in_seq = Input(shape=(seq_len, 9))\n",
    "  x = time_embedding(in_seq)\n",
    "  x = normal_batch(x)\n",
    "  x = Concatenate(axis=-1)([in_seq, x])\n",
    "  x = normal_first(x)\n",
    "  x = normall(x)\n",
    "  x = attn_layer1((x, x, x))\n",
    "  x = normal_batch(x)\n",
    "  x = normall(x)\n",
    "  # x = sce2(x)\n",
    "  # print(x.shape)\n",
    "  x = attn_layer2((x, x, x))\n",
    "  x = normall(x)\n",
    "  # x = sce2(x)\n",
    "  x = attn_layer3((x, x, x))\n",
    "  \n",
    "  x = normall(x)\n",
    "  x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "  x = normal_batch(x)\n",
    "  x = Dropout(0.1)(x)\n",
    "  x = Dense(64, activation='relu')(x)\n",
    "  x = Dropout(0.1)(x)\n",
    "  out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "  model = Model(inputs=in_seq, outputs=out)\n",
    "  model.compile(loss=losses.binary_crossentropy, optimizer='adam', metrics=['mae', 'mape'])\n",
    "  return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint('./Transformer+TimeEmbedding_sz.hdf5', \n",
    "                                              monitor='val_loss', \n",
    "                                              save_best_only=True, \n",
    "                                              verbose=1)\n",
    "\n",
    "# callback = tf.keras.callbacks.ModelCheckpoint('Transformer+TimeEmbedding.hdf5', \n",
    "#                                               monitor='mae', \n",
    "#                                               save_best_only=False, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, \n",
    "                    epochs=300,\n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./Transformer+TimeEmbedding_sz.hdf5',\n",
    "                                   custom_objects={'Time2Vector': Time2Vector, \n",
    "                                                   'SingleAttention': SingleAttention,\n",
    "                                                   'MultiAttention': MultiAttention,\n",
    "                                                   'TransformerEncoder': TransformerEncoder})\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "'''Calculate predictions and metrics'''\n",
    "\n",
    "#Calculate predication for training, validation and test data\n",
    "train_pred = model.predict(X_train)\n",
    "val_pred = model.predict(X_val)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "#Print evaluation metrics for all datasets\n",
    "train_eval = model.evaluate(X_train, y_train, verbose=0)\n",
    "val_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "test_eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(' ')\n",
    "print('Evaluation metrics')\n",
    "print('Training Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(train_eval[0], train_eval[1], train_eval[2]))\n",
    "print('Validation Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(val_eval[0], val_eval[1], val_eval[2]))\n",
    "print('Test Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(test_eval[0], test_eval[1], test_eval[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Display results'''\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Transformer + TimeEmbedding Model\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(train_data[:, 3], label='Tesla Closing Returns')\n",
    "ax11.plot(np.arange(seq_len, train_pred.shape[0]+seq_len), train_pred, linewidth=3, label='Predicted Tesla Closing Returns')\n",
    "ax11.set_title(\"Training Data\", fontsize=18)\n",
    "ax11.set_xlabel('Date')\n",
    "ax11.set_ylabel('Tesla Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot validation data results\n",
    "ax21 = fig.add_subplot(312)\n",
    "ax21.plot(val_data[:, 3], label='Tesla Closing Returns')\n",
    "ax21.plot(np.arange(seq_len, val_pred.shape[0]+seq_len), val_pred, linewidth=3, label='Predicted Tesla Closing Returns')\n",
    "ax21.set_title(\"Validation Data\", fontsize=18)\n",
    "ax21.set_xlabel('Date')\n",
    "ax21.set_ylabel('Tesla Closing Returns')\n",
    "ax21.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot test data results\n",
    "ax31 = fig.add_subplot(313)\n",
    "ax31.plot(test_data[:, 3], label='Tesla Closing Returns')\n",
    "ax31.plot(np.arange(seq_len, test_pred.shape[0]+seq_len), test_pred, linewidth=3, label='Predicted Tesla Closing Returns')\n",
    "ax31.set_title(\"Test Data\", fontsize=18)\n",
    "ax31.set_xlabel('Date')\n",
    "ax31.set_ylabel('Tesla Closing Returns')\n",
    "ax31.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQxwsG_AT_gm"
   },
   "source": [
    "## Moving Average - Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[-1],test_pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_accuracy(real, predict):\n",
    "#     real = np.array(real) + 1\n",
    "#     predict = np.array(predict) + 1\n",
    "#     percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "#     return percentage * 100\n",
    "# accuracies = [calculate_accuracy(df['Close'].iloc[-y_test.size:].values, r) for r in test_pred]\n",
    "count = 0\n",
    "for i in range(len(y_test.size)):\n",
    "    if charge(test_pred[i])==y_test[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is %.4f\"%(count/len(y_test)))\n",
    "# plt.figure(figsize = (15, 5))\n",
    "# plt.plot(test_pred[:y_test.size], label = 'forecast')\n",
    "# plt.plot(df['Close'].iloc[:y_test.size].values, label = 'true trend', c = 'black')\n",
    "# plt.legend()\n",
    "# plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UCNT45C_TjsT",
    "outputId": "593aec95-a2c2-4f0d-8845-70d5ee3a74a3"
   },
   "outputs": [],
   "source": [
    "'''Display model metrics'''\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Moving Average - Transformer + TimeEmbedding Model Metrics\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot model loss\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.plot(history.history['loss'], label='Training loss (MSE)')\n",
    "ax1.plot(history.history['val_loss'], label='Validation loss (MSE)')\n",
    "ax1.set_title(\"Model loss\", fontsize=18)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot MAE\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.plot(history.history['mae'], label='Training MAE')\n",
    "ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax2.set_title(\"Model metric - Mean average error (MAE)\", fontsize=18)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Mean average error (MAE)')\n",
    "ax2.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot MAPE\n",
    "ax3 = fig.add_subplot(313)\n",
    "ax3.plot(history.history['mape'], label='Training MAPE')\n",
    "ax3.plot(history.history['val_mape'], label='Validation MAPE')\n",
    "ax3.set_title(\"Model metric - Mean average percentage error (MAPE)\", fontsize=18)\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Mean average percentage error (MAPE)')\n",
    "ax3.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNvUgwyfTjl0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IBM_Transformer+TimeEmbedding_Github.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
